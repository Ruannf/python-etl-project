# ETL Pipeline em Python para Carga de Dados no SQL Server

Este projeto implementa um pipeline **ETL completo (Extract â†’ Transform â†’ Load)** utilizando **Python, Pandas e SQLAlchemy**, com o objetivo de automatizar a ingestÃ£o de dados provenientes de arquivos CSV para uma tabela SQL Server.

O cÃ³digo foi estruturado seguindo boas prÃ¡ticas de Engenharia de Dados, permitindo fÃ¡cil manutenÃ§Ã£o, expansÃ£o e integraÃ§Ã£o com orquestradores.

---

## ğŸ“‘ Ãndice

## Ãndice
- [VisÃ£o Geral](#visÃ£o-geral)
- [Arquitetura do Projeto](#arquitetura-do-projeto)
- [Tecnologias Utilizadas](#tecnologias-utilizadas)
- [Funcionalidades](#funcionalidades)
- [Estrutura de Pastas](#estrutura-de-pastas)
- [Como Executar](#como-executar)
- [ConfiguraÃ§Ã£o do Ambiente (.env)](#configuraÃ§Ã£o-do-ambiente-env)
- [Exemplo de Dados](#exemplo-de-dados)
- [Logs do Pipeline](#logs-do-pipeline)
- [Melhorias Futuras](#melhorias-futuras)


---

## VisÃ£o Geral

O pipeline realiza:

- **Leitura** segura de um CSV
- **Tratamento e padronizaÃ§Ã£o** dos dados
- **TransformaÃ§Ãµes** (datas, booleanos, renomeaÃ§Ãµes)
- **InserÃ§Ã£o** no banco SQL Server com tratamento de erros
- **Registro de logs** detalhados de todas as etapas do processo

---

## Arquitetura do Projeto
CSV â†’ Extract (Pandas) â†’ Transform â†’ Load (SQLAlchemy) â†’ SQL Server

---

## Tecnologias Utilizadas

- **Python 3.11+**
- **Pandas**
- **SQLAlchemy**
- **PyODBC**
- **python-dotenv**
- **SQL Server**
- **VSCode** (desenvolvimento)

---

## Funcionalidades

### âœ” Extract
- Leitura do CSV com validaÃ§Ãµes
- Tratamento de arquivos vazios ou inexistentes
- PadronizaÃ§Ã£o automÃ¡tica dos nomes das colunas
- ConversÃ£o inicial de tipos

### âœ” Transform
- RenomeaÃ§Ã£o de colunas para padrÃ£o do banco
- Ajuste de datas
- ConversÃ£o de campos booleanos
- InclusÃ£o de metadados:
  - `UPLOAD_DATE`
  - `UPLOAD_BY`

### âœ” Load
- ConexÃ£o com SQL Server via SQLAlchemy + PyODBC
- InserÃ§Ã£o com `if_exists='append'`
- Logs claros sobre sucesso e falha
- Tratamento de exceÃ§Ãµes

---

## Estrutura de Pastas

ETL/
â”œâ”€â”€ Main.py # Orquestra o pipeline completo
â”œâ”€â”€ Extract.py # FunÃ§Ãµes de extraÃ§Ã£o
â”œâ”€â”€ Transform.py # FunÃ§Ãµes de transformaÃ§Ã£o
â”œâ”€â”€ Load.py # FunÃ§Ãµes de carga
â”œâ”€â”€ arquivos/
â”‚ â””â”€â”€ employees_data.csv
â”œâ”€â”€ acesso.env # VariÃ¡veis de ambiente
â””â”€â”€ README.md

---

## â–¶ Como Executar

### 1ï¸âƒ£ Criar ambiente virtual (opcional, recomendado)

python -m venv venv
venv\Scripts\activate   # Windows

### 2ï¸âƒ£ DependÃªncias do Projeto
Python 3.x
Pandas â€” leitura e manipulaÃ§Ã£o de dados
SQLAlchemy â€” engine e conexÃ£o com SQL Server
PyODBC â€” driver ODBC para integraÃ§Ã£o com SQL Server
Python-dotenv â€” carregamento de variÃ¡veis de ambiente

### 3ï¸âƒ£ Configurar variÃ¡veis de ambiente
Crie um arquivo acesso.env:

DRIVER=ODBC Driver 17 for SQL Server
SERVER=SEU_SERVIDOR
DATABASE=SUA_BASE
UID=SEU_USUARIO
PWD=SUA_SENHA
USUARIO_UPLOAD=SEU_NOME

### 4ï¸âƒ£ Executar o pipeline
python Main.py

### Logs do Pipeline

ğŸŸ¦ Iniciando processo ETL...
ğŸ“¥ Extraindo dados do CSV tratado...
âœ” 100 linhas extraÃ­das com sucesso.
ğŸ›  Aplicando transformaÃ§Ãµes e padronizaÃ§Ãµes no DataFrame...
âœ” 100 registros prontos para inserÃ§Ã£o.
ğŸ“¤ Iniciando etapa de upload para o banco...
âœ” 100 registros inseridos na tabela [TBL_EMPLOYEES].
ğŸ Processo ETL finalizado com sucesso!

